#!/usr/bin/env python3
"""
Speech Command App - Main Entry Point

A hands-free speech-to-text application with correction commands.

Usage:
    python main.py [--debug] [--hotkey "<cmd>+<shift>+<space>"]

Workflow:
    1. Press hotkey to start recording
    2. Speak your text in Chinese
    3. Press hotkey again to stop and process
    4. Text is typed at cursor position
    5. To correct: speak a command like "æŠŠXæ”¹æˆY"
"""
# Suppress noisy warnings from transformers about beta/gamma parameter renaming
import warnings
warnings.filterwarnings("ignore", message=".*beta.*renamed.*bias.*")
warnings.filterwarnings("ignore", message=".*gamma.*renamed.*weight.*")

import argparse
import signal
import sys
import threading
import time
from pathlib import Path
from PIL import Image
import pystray
from typing import Optional, Any

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent))

from config import config, Config
from services.audio_recorder import AudioRecorder
from services.whisper_service import WhisperService
from services.command_processor import CommandProcessor
from services.rule_based_processor import RuleBasedProcessor
from services.gemini_processor import GeminiProcessor
from utils.hotkey_manager import HotkeyManager
from utils.keyboard_simulator import KeyboardSimulator


class SpeechCommandApp:
    """
    Main application class for speech-to-text with command correction.
    """

    def __init__(self, debug_mode: bool = None, hotkey: str = None, stt_backend: str = None, no_ml: bool = False, use_api: bool = False):
        """
        Initialize the application.

        Args:
            debug_mode: Enable debug overlay (default: from config)
            hotkey: Custom hotkey (default: from config)
            stt_backend: STT backend ("whisper" or "funasr", default: from config)
            no_ml: Use rule-based processor instead of BERT model (default: False)
            use_api: Use Gemini API for processing (default: False)
        """
        self.debug_mode = debug_mode if debug_mode is not None else config.DEBUG_MODE
        self.hotkey = hotkey or config.HOTKEY
        self.stt_backend = stt_backend or config.STT_BACKEND
        self.no_ml = no_ml
        self.use_api = use_api


        #icon images
        self.tray_icon: Optional[pystray.Icon] = None
        self.ready_icon_img: Optional[Image.Image] = None # éœæ…‹ï¼ˆç™½ï¼‰åœ–æ¨™
        self.recording_icon_img: Optional[Image.Image] = None # éŒ„è£½ä¸­ï¼ˆç´…ï¼‰åœ–æ¨™
        self.placeholder_icon_img: Optional[Image.Image] = None # å‚™ç”¨åœ–

        # icon blink state
        self._blink_timer = None
        self._blink_state = False

        # State
        self.is_recording = False
        self.last_typed_text = ""
        self._lock = threading.Lock()

        # Services (lazy loaded)
        self._recorder = None
        self._stt = None
        self._processor = None
        self._hotkey_manager = None
        self._keyboard = None

        

    @property
    def recorder(self) -> AudioRecorder:
        if self._recorder is None:
            self._recorder = AudioRecorder()
        return self._recorder

    @property
    def stt(self):
        """Get the STT service (Whisper or FunASR)."""
        if self._stt is None:
            if self.stt_backend == "funasr":
                from services.funasr_service import FunASRService
                self._stt = FunASRService(model_name=config.FUNASR_MODEL)
            else:
                self._stt = WhisperService()
        return self._stt

    # Keep whisper property for backward compatibility
    @property
    def whisper(self):
        return self.stt

    @property
    def processor(self):
        """Get the command processor (API, rule-based, or ML-based)."""
        if self._processor is None:
            if self.use_api:
                self._processor = GeminiProcessor()
            elif self.no_ml:
                self._processor = RuleBasedProcessor()
            else:
                self._processor = CommandProcessor()
        return self._processor

    @property
    def keyboard(self) -> KeyboardSimulator:
        if self._keyboard is None:
            self._keyboard = KeyboardSimulator()
        return self._keyboard

    def _show_status(self, message: str) -> None:
        """Show status message and update tray icon title."""
        print(f"[STATUS] {message}")
        # [æœ€å°åŒ–ä¿®æ”¹ï¼šæ–°å¢ Pystray ç‹€æ…‹æ›´æ–°]
        if self.tray_icon:
            self.tray_icon.title = f"Speech App - {message}"

    def _hide_status(self) -> None:
        """Hide status (update tray title to 'Ready')."""
        # [æœ€å°åŒ–ä¿®æ”¹ï¼šæ–°å¢ Pystray ç‹€æ…‹æ›´æ–°]
        self._show_status("Ready")

    '''    
    def on_hotkey(self) -> None:
        """Handle hotkey press - toggle recording."""
        with self._lock:
            if not self.is_recording:
                self._start_recording()
            else:
                self._stop_and_process()
    '''
    def get_toggle_text(self, icon: Any) -> str:
        """Dynamically set the menu text based on recording state."""
        if self.is_recording:
            return 'Stop Recording'
        # ä¿ç•™ hotkey æç¤º
        return f'Start Recording ({self.hotkey})'

    def _load_icon_safe(self, filename: str) -> Optional[Image.Image]:
        icon_path = Path(__file__).parent / filename
        try:
            img = Image.open(icon_path)
            print(f"Icon loaded successfully from: {icon_path}")
            return img
        except FileNotFoundError:
            print(f"âš ï¸ Warning: Icon file not found at {icon_path}.")
        except Exception as e:
            print(f"âš ï¸ Warning: Failed to load icon image '{filename}': {e.__class__.__name__}.")
        return None


    def setup_tray(self) -> None:
        # 1. è¼‰å…¥éœæ…‹ï¼ˆReadyï¼‰å’ŒéŒ„è£½ä¸­ï¼ˆRecordingï¼‰åœ–æ¨™
        self.ready_icon_img = self._load_icon_safe("speech-synthesis.png")
        self.recording_icon_img = self._load_icon_safe("speech-synthesis_red.png")
        
        # 2. å»ºç«‹å‚™ç”¨åœ–æ¨™ (å¦‚æœè¼‰å…¥å¤±æ•—)
        if not self.ready_icon_img:
            self.placeholder_icon_img = Image.new('RGB', (16, 16), (255, 255, 255))
            self.ready_icon_img = self.placeholder_icon_img
        if not self.recording_icon_img:
            # å¦‚æœç´…è‰²åœ–æ¨™éºå¤±ï¼Œé€€å›åˆ°ä¸€å€‹å¯¦å¿ƒç´…è‰²æ–¹å¡Š
            self.recording_icon_img = Image.new('RGB', (16, 16), (255, 0, 0))
            
        # 3. å‰µå»ºèœå–® (ä¿æŒä¸è®Š)
        menu = pystray.Menu(
            pystray.MenuItem(text=self.get_toggle_text, action=self.on_hotkey),
            pystray.Menu.SEPARATOR,
            pystray.MenuItem(text='âŒ Exit', action=self.cleanup_and_exit)
        )
        
        # 4. å‰µå»º Pystray å¯¦ä¾‹ï¼Œä½¿ç”¨ Ready Icon ä½œç‚ºåˆå§‹åœ–æ¨™
        self.tray_icon = pystray.Icon(
            name="SpeechCommandApp", 
            icon=self.ready_icon_img, # ä½¿ç”¨è¼‰å…¥çš„ç™½è‰²åœ–æ¨™ä½œç‚ºåˆå§‹ç‹€æ…‹
            title="Speech App - Initializing...",
            menu=menu
        )
        self.tray_icon.title = "Speech App - Ready"

    def cleanup_and_exit(self, icon: pystray.Icon, item: pystray.MenuItem) -> None:
        """åœæ­¢åœ–æ¨™ä¸¦é€€å‡ºç¨‹å¼ (ç”¨æ–¼èœå–®é€€å‡º)ã€‚"""
        print("\nExiting via System Tray Menu...")
        self.cleanup()
        if icon:
            icon.stop()
        sys.exit(0)

    #new version 
    def on_hotkey(self, icon: Optional[pystray.Icon]=None, item: Optional[pystray.MenuItem]=None) -> None:
        """Handle hotkey press - toggle recording (Fast Toggle)."""
        
        if not self.is_recording:
            self._start_recording()
        else:
            self._stop_and_process() 

    def _start_recording(self) -> None:
        """Start audio recording."""
        self.is_recording = True
        self._show_status("Recording...")
        self.recorder.start()
    '''
    def _stop_and_process(self) -> None:
        """Stop recording and process the audio."""
        self.is_recording = False
        self._show_status("Processing...")

        # Stop recording
        audio_path = self.recorder.stop()

        try:
            # Transcribe audio
            self._show_status("Transcribing...")
            text = self.whisper.transcribe(audio_path)

            if not text:
                self._show_status("No speech detected")
                time.sleep(1)
                self._hide_status()
                return

            self._show_status(f"Heard: {text}")

            # Check if this is a correction command
            if self.processor.is_command(text):
                # First, check if user has selected text to correct
                selected_text = self.keyboard.get_selected_text()
                target_text = selected_text if selected_text else self.last_typed_text
                has_selection = bool(selected_text)

                self._show_status(f"Applying correction to: '{target_text}' (selected: {has_selection})")
                result, was_command = self.processor.process(text, target_text)
                self._show_status(f"Result: '{result}', was_command: {was_command}")

                if was_command and target_text:
                    if has_selection:
                        # Replace selected text directly (typing replaces selection)
                        self.keyboard.replace_selection(result)
                    else:
                        # Delete old text and type corrected version
                        self.keyboard.replace_last_typed(target_text, result)
                    self.last_typed_text = result
                    self._show_status(f"Corrected: {result}")
                else:
                    # Couldn't apply correction, type as-is
                    self.keyboard.type_text(text)
                    self.last_typed_text = text
            else:
                # Normal dictation - just type the text
                self._show_status(f"Typing: {text}")
                try:
                    self.keyboard.type_text(text)
                    self.last_typed_text = text
                    self._show_status(f"Typed: {text}")
                except Exception as e:
                    self._show_status(f"Typing failed: {e}")
                    print(f"Typing error: {e}")

            time.sleep(0.5)
            self._hide_status()

        except Exception as e:
            self._show_status(f"Error: {e}")
            print(f"Error processing speech: {e}")
            time.sleep(2)
            self._hide_status()
    '''
    def _stop_and_process(self) -> None:
        """Stop recording, set state, and launch core processing thread."""
        
        # 1. ç«‹å³è¨­å®šç‹€æ…‹ç‚ºééŒ„éŸ³ï¼Œé‡‹æ”¾çµ¦ä¸‹ä¸€å€‹ F9
        self.is_recording = False
        self._show_status("Processing...")
        
        if self._blink_timer:
            self._blink_timer.cancel()
            self._blink_timer = None
        self._set_static_icon()
        # 2. å°‡æ ¸å¿ƒé‚è¼¯ä¸Ÿçµ¦æ–°çš„åŸ·è¡Œç·’è™•ç†
        process_thread = threading.Thread(target=self._stop_and_process_core)
        process_thread.start()

    def _stop_and_process_core(self) -> None:
        """Core logic for stopping recording and processing audio (runs in thread)."""
        
        with self._lock: 
            # Stop recording
            audio_path = self.recorder.stop()

        try:
            # Transcribe audio
            self._show_status("Transcribing...")
            text = self.whisper.transcribe(audio_path)

            if not text:
                self._show_status("No speech detected")
                time.sleep(1)
                self._hide_status()
                return

            self._show_status(f"Heard: {text}")

            # Check if this is a correction command
            if self.processor.is_command(text):
                # First, check if user has selected text to correct
                selected_text = self.keyboard.get_selected_text()
                target_text = selected_text if selected_text else self.last_typed_text
                has_selection = bool(selected_text)

                self._show_status(f"Applying correction to: '{target_text}' (selected: {has_selection})")
                result, was_command = self.processor.process(text, target_text)
                self._show_status(f"Result: '{result}', was_command: {was_command}")

                if was_command and target_text:
                    if has_selection:
                        # Replace selected text directly (typing replaces selection)
                        self.keyboard.replace_selection(result)
                    else:
                        # Delete old text and type corrected version
                        self.keyboard.replace_last_typed(target_text, result)
                    self.last_typed_text = result
                    self._show_status(f"Corrected: {result}")
                else:
                    # Couldn't apply correction, type as-is
                    self.keyboard.type_text(text)
                    self.last_typed_text = text
            else:
                # Normal dictation - just type the text
                self._show_status(f"Typing: {text}")
                try:
                    self.keyboard.type_text(text)
                    self.last_typed_text = text
                    self._show_status(f"Typed: {text}")
                except Exception as e:
                    self._show_status(f"Typing failed: {e}")
                    print(f"Typing error: {e}")

            time.sleep(0.5)
            self._hide_status()

        except Exception as e:
            self._show_status(f"Error: {e}")
            print(f"Error processing speech: {e}")
            time.sleep(2)
            self._hide_status()

    def _preload_models(self) -> None:
        """Preload models for faster first inference."""
        print("Preloading models...")
        self.whisper.load()
        self.processor.labeler.load()
        print("Models loaded!")

    def run(self) -> None:
        """Run the application."""
        print("=" * 60)
        print(f"ğŸ™ï¸ Speech Command App starting...")
        
        # Preload models
        self._preload_models()

        # [æ–°å¢ Pystray å•Ÿå‹•]
        self.setup_tray()
        # [çµæŸ Pystray å•Ÿå‹•]

        # å•Ÿå‹• Hotkey Manager
        self._hotkey_manager = HotkeyManager(hotkey=self.hotkey, callback=self.on_hotkey)
        self._hotkey_manager.start()

        print(f"Hotkey Registered: {self.hotkey}")
        # é¡¯ç¤ºåˆå§‹ç‹€æ…‹
        self._show_status("Ready")

        # [ä¿®æ”¹ä¸»è¿´åœˆ]
        # å…¼å®¹ Mac/Winï¼šè®“ Pystray åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­é‹è¡Œ (run_detached)
        self.tray_icon.run_detached()

        print("System Tray icon running. Use 'Exit' in the menu to close.")
        print("=" * 60)
        
        try:
            # Pystray åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­ï¼Œæˆ‘å€‘æ‰‹å‹•è®“ä¸»ç·šç¨‹ä¿æŒæ´»èº
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nReceived Ctrl+C, shutting down...")
        finally:
            self.cleanup()
            if self.tray_icon:
                self.tray_icon.stop() # ç¢ºä¿åœæ­¢ Pystray
            sys.exit(0)

    def cleanup(self) -> None:
        """Clean up resources."""
        if self._hotkey_manager:
            self._hotkey_manager.stop()
            
        if self._recorder:
            self._recorder.cleanup()

        if self._blink_timer:
            self._blink_timer.cancel()
            self._blink_timer = None
        
        if self.tray_icon:
            self.tray_icon.stop()
    

    def _get_recording_icon_image(self) -> Image.Image:
        """è¿”å›ç´…è‰²çš„ Recording åœ–æ¨™ (ç”¨æ–¼é–ƒçˆçš„ 'on' ç‹€æ…‹)ã€‚"""
        # ä½¿ç”¨ä¸€å€‹ 16x16 çš„å¯¦å¿ƒç´…è‰²æ–¹å¡Šä¾†å¯¦ç¾é«˜å°æ¯”åº¦é–ƒçˆ
        return Image.new('RGB', (16, 16), (255, 0, 0))

    def _set_static_icon(self) -> None:
        """å°‡åœ–æ¨™è¨­å›éœæ…‹çš„ Ready ç‹€æ…‹ (ä½¿ç”¨è‡ªå®šç¾©çš„ Ready åœ–æ¨™)ã€‚"""
        if self.tray_icon and self.ready_icon_img:
            self.tray_icon.icon = self.ready_icon_img


    def _blink_icon_toggle(self) -> None:
        """å®šæ™‚å™¨è§¸ç™¼ï¼Œåˆ‡æ›ç³»çµ±è¨—ç›¤åœ–æ¨™çš„å¤–è§€ (ç´…ç™½åˆ‡æ›)ã€‚"""
        if not self.is_recording or not self.tray_icon:
            self._set_static_icon()
            return

        if self._blink_state:
            # ç‹€æ…‹ A: é¡¯ç¤ºç‚ºç™½è‰²ï¼ˆReadyï¼‰åœ–æ¨™
            self.tray_icon.icon = self.ready_icon_img
        else:
            # ç‹€æ…‹ B: é¡¯ç¤ºç‚ºç´…è‰²ï¼ˆRecordingï¼‰åœ–æ¨™
            self.tray_icon.icon = self.recording_icon_img
            
        self._blink_state = not self._blink_state # åˆ‡æ›ç‹€æ…‹
        
        # [é‡è¦] é‡æ–°å•Ÿå‹•å®šæ™‚å™¨ä»¥ç¹¼çºŒé–ƒçˆ (0.5 ç§’åˆ‡æ›ä¸€æ¬¡)
        self._blink_timer = threading.Timer(0.5, self._blink_icon_toggle) 
        self._blink_timer.start()

    # main.py (åœ¨ _start_recording å‡½å¼å…§ï¼Œç´„ 195 è¡Œè™•)

    def _start_recording(self) -> None:
        """Start audio recording."""
        self.is_recording = True
        self._show_status("Recording...")
        self.recorder.start()
        
        # [æ–°å¢] å•Ÿå‹•é–ƒçˆå®šæ™‚å™¨
        self._blink_state = False 
        self._blink_icon_toggle() # ç«‹å³å•Ÿå‹•ç¬¬ä¸€æ¬¡åˆ‡æ›å’Œå®šæ™‚å™¨

    


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Speech-to-text with correction commands"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Enable debug mode with status overlay"
    )
    parser.add_argument(
        "--no-debug",
        action="store_true",
        help="Disable debug mode"
    )
    parser.add_argument(
        "--hotkey",
        type=str,
        default=None,
        help="Custom hotkey (e.g., '<cmd>+<shift>+<space>')"
    )
    parser.add_argument(
        "--stt",
        type=str,
        choices=["whisper", "funasr"],
        default=None,
        help="STT backend: 'whisper' (default) or 'funasr' (Paraformer)"
    )
    parser.add_argument(
        "--notML",
        action="store_true",
        help="Use rule-based processor instead of BERT model (faster, no GPU needed)"
    )
    parser.add_argument(
        "--api",
        action="store_true",
        help="Use Gemini API for intelligent correction (requires internet)"
    )

    args = parser.parse_args()

    # Determine debug mode
    debug_mode = None
    if args.debug:
        debug_mode = True
    elif args.no_debug:
        debug_mode = False

    # Create and run app
    app = SpeechCommandApp(
        debug_mode=debug_mode,
        hotkey=args.hotkey,
        stt_backend=args.stt,
        no_ml=args.notML,
        use_api=args.api
    )

    # Handle signals
    def signal_handler(sig, frame):
        print("\nReceived interrupt signal, shutting down...")
        app.cleanup()
        sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    app.run()


if __name__ == "__main__":
    main()


